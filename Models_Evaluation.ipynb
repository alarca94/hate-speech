{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluation, composition\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "N_FOLDS = 5\n",
    "RANDOM_SEED = 32\n",
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>text</th>\n",
       "      <th>constructive</th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxicity_degree</th>\n",
       "      <th>sarcasm_irony</th>\n",
       "      <th>mockery_ridicule</th>\n",
       "      <th>insults</th>\n",
       "      <th>argument_discussion</th>\n",
       "      <th>negative_toxic_lang</th>\n",
       "      <th>aggressiveness</th>\n",
       "      <th>intolerance</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Con un poco de suerte si esto sigue a este rit...</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>INMIGRACIÓN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Telita con el artículo. No sé bien si lo que s...</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>INMIGRACIÓN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-bis</td>\n",
       "      <td>Que eso ocurra en algunos casos es posible, cl...</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>INMIGRACIÓN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Al menos en Francia tienen el Frente Nacional,...</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>INMIGRACIÓN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-bis</td>\n",
       "      <td>Cuando dejen de soplar los vientos de cola ( p...</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SÍ</td>\n",
       "      <td>INMIGRACIÓN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_id                                               text constructive  \\\n",
       "0         1  Con un poco de suerte si esto sigue a este rit...           NO   \n",
       "1         2  Telita con el artículo. No sé bien si lo que s...           SÍ   \n",
       "2     2-bis  Que eso ocurra en algunos casos es posible, cl...           SÍ   \n",
       "3         3  Al menos en Francia tienen el Frente Nacional,...           NO   \n",
       "4     3-bis  Cuando dejen de soplar los vientos de cola ( p...           NO   \n",
       "\n",
       "  toxic  toxicity_degree sarcasm_irony mockery_ridicule insults  \\\n",
       "0    SÍ                2            NO               NO      NO   \n",
       "1    NO                1            NO               NO      NO   \n",
       "2    SÍ                2            NO               NO      NO   \n",
       "3    SÍ                3            NO               SÍ      SÍ   \n",
       "4    SÍ                2            NO               NO      NO   \n",
       "\n",
       "  argument_discussion negative_toxic_lang aggressiveness intolerance  \\\n",
       "0                  NO                  NO             NO          SÍ   \n",
       "1                  SÍ                  NO             NO          NO   \n",
       "2                  SÍ                  NO             NO          NO   \n",
       "3                  NO                  SÍ             NO          NO   \n",
       "4                  SÍ                  NO             NO          SÍ   \n",
       "\n",
       "           type  \n",
       "0  INMIGRACIÓN  \n",
       "1  INMIGRACIÓN  \n",
       "2  INMIGRACIÓN  \n",
       "3  INMIGRACIÓN  \n",
       "4  INMIGRACIÓN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data to be processed\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, 'gold_standard_27maig2020.csv'), sep='|')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the general evaluation configuration\n",
    "eval_config = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'basic_manual_both': 0,\n",
    "    'log': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.2, 'bootstrap': True, 'criterion': 'gini', 'n_feats': 'sqrt', 'n_trees': 75, 'name': 'Random Forest', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.19264520452058162 ± 0.006437195293397951\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Random Forest'\n",
    "params = {'name': [model_name],\n",
    "        'n_trees': [75, 100, 150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'n_feats': ['sqrt', 'log2'],\n",
    "        'PCA_components': [0.2, 0.5, 0.8],\n",
    "        'svd_solver': ['full'],\n",
    "        'bootstrap': [True],\n",
    "        'strip_accents': [None],\n",
    "        'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'decision_func': 'ovr', 'gamma': 'scale', 'kernel': 'rbf', 'name': 'SVC', 'penalty': 100, 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.25309968755591344 ± 0.015773275614319453\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "params = {'name': [model_name],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'decision_func': ['ovr', 'ovo'],\n",
    "    'PCA_components': [0.5],\n",
    "    'svd_solver': ['full'],\n",
    "    'penalty': [1, 100],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.8, 'multi_class': 'auto', 'name': 'Logistic Regression', 'penalty': 'l2', 'solver': 'lbfgs', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.19517586120574204 ± 0.008952963441622845\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Logistic Regression'\n",
    "params = {'name': [model_name],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'multi_class': ['auto'],\n",
    "    'PCA_components': [0.5, 0.8],\n",
    "    'svd_solver': ['full'],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if the number of PCA components is drastically reduced? \n",
    "### (accuracy is still the performance score in this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Fold 1 is: 0.5692\n",
      "Accuracy for Fold 2 is: 0.5613\n",
      "Accuracy for Fold 3 is: 0.5692\n",
      "Accuracy for Fold 4 is: 0.5992\n",
      "Accuracy for Fold 5 is: 0.6032\n",
      "Total Prediction Accuracy is: 0.5804 ± 0.0173\n"
     ]
    }
   ],
   "source": [
    "# Now let's try diminishing the number of PCA components drastically\n",
    "model_name = 'Random Forest'\n",
    "\n",
    "params = {}\n",
    "model_config = {'criterion': [],\n",
    "                'n_trees': [],\n",
    "                \n",
    "    'name': model_name,\n",
    "    'n_trees': 150,\n",
    "    'criterion': 'gini',\n",
    "    'n_feats': 3,\n",
    "    'PCA_components': 10,\n",
    "    'svd_solver': 'full',\n",
    "    'bootstrap': True\n",
    "}\n",
    "\n",
    "evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Fold 1 is: 0.5889\n",
      "Accuracy for Fold 2 is: 0.5889\n",
      "Accuracy for Fold 3 is: 0.5929\n",
      "Accuracy for Fold 4 is: 0.5952\n",
      "Accuracy for Fold 5 is: 0.5952\n",
      "Total Prediction Accuracy is: 0.5922 ± 0.0028\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "model_config = {\n",
    "    'name': model_name,\n",
    "    'kernel': 'linear',\n",
    "    'gamma': 'auto',\n",
    "    'decision_func': 'ovr',\n",
    "    'PCA_components': 10,\n",
    "    'svd_solver': 'full',\n",
    "    'penalty': 100\n",
    "}\n",
    "\n",
    "evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Fold 1 is: 0.5889\n",
      "Accuracy for Fold 2 is: 0.5889\n",
      "Accuracy for Fold 3 is: 0.5889\n",
      "Accuracy for Fold 4 is: 0.5952\n",
      "Accuracy for Fold 5 is: 0.5952\n",
      "Total Prediction Accuracy is: 0.5915 ± 0.0031\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Logistic Regression'\n",
    "model_config = {\n",
    "    'name': model_name,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'lbfgs',\n",
    "    'PCA_components': 10,\n",
    "    'svd_solver': 'full',\n",
    "    'multi_class': 'auto'\n",
    "}\n",
    "\n",
    "evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the general evaluation configuration\n",
    "eval_config = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'basic_manual_both': 1,\n",
    "    'log': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.2, 'bootstrap': True, 'criterion': 'gini', 'n_feats': 'sqrt', 'n_trees': 75, 'name': 'Random Forest', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.6469567043511599 ± 0.029735920331835315\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Random Forest'\n",
    "params = {'name': [model_name],\n",
    "        'n_trees': [75, 100, 150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'n_feats': ['sqrt', 'log2'],\n",
    "        'PCA_components': [0.2, 0.5, 0.8],\n",
    "        'svd_solver': ['full'],\n",
    "        'bootstrap': [True],\n",
    "        'strip_accents': [None],\n",
    "        'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'decision_func': 'ovr', 'gamma': 'auto', 'kernel': 'linear', 'name': 'SVC', 'penalty': 100, 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.7131239361859932 ± 0.024950245497339693\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "params = {'name': [model_name],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'decision_func': ['ovr', 'ovo'],\n",
    "    'PCA_components': [0.5],\n",
    "    'svd_solver': ['full'],\n",
    "    'penalty': [1, 100],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'multi_class': 'auto', 'name': 'Logistic Regression', 'penalty': 'l2', 'solver': 'lbfgs', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.6980215743408402 ± 0.030822866545072287\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Logistic Regression'\n",
    "params = {'name': [model_name],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'multi_class': ['auto'],\n",
    "    'PCA_components': [0.5, 0.8],\n",
    "    'svd_solver': ['full'],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf plus Manual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the general evaluation configuration\n",
    "eval_config = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'basic_manual_both': 2,\n",
    "    'log': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.2, 'bootstrap': True, 'criterion': 'entropy', 'n_feats': 'log2', 'n_trees': 150, 'name': 'Random Forest', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.6107953119440055 ± 0.038566543239510906\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Random Forest'\n",
    "params = {'name': [model_name],\n",
    "        'n_trees': [75, 100, 150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'n_feats': ['sqrt', 'log2'],\n",
    "        'PCA_components': [0.2, 0.5, 0.8],\n",
    "        'svd_solver': ['full'],\n",
    "        'bootstrap': [True],\n",
    "        'strip_accents': [None],\n",
    "        'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'decision_func': 'ovr', 'gamma': 'auto', 'kernel': 'sigmoid', 'name': 'SVC', 'penalty': 100, 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.6958708872673602 ± 0.03383274832104306\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "params = {'name': [model_name],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'decision_func': ['ovr', 'ovo'],\n",
    "    'PCA_components': [0.5],\n",
    "    'svd_solver': ['full'],\n",
    "    'penalty': [1, 100],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'multi_class': 'auto', 'name': 'Logistic Regression', 'penalty': 'l2', 'solver': 'lbfgs', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.7053333878582009 ± 0.04219655242386391\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Logistic Regression'\n",
    "params = {'name': [model_name],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'multi_class': ['auto'],\n",
    "    'PCA_components': [0.5, 0.8],\n",
    "    'svd_solver': ['full'],\n",
    "    'strip_accents': [None],\n",
    "    'stop_words': [None]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf stripping accents and removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the general evaluation configuration\n",
    "eval_config = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'basic_manual_both': 0,\n",
    "    'log': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.2, 'bootstrap': True, 'criterion': 'gini', 'n_feats': 'sqrt', 'n_trees': 100, 'name': 'Random Forest', 'strip_accents': 'unicode', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.19288771888606082 ± 0.0038792641586980602\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Random Forest'\n",
    "params = {'name': [model_name],\n",
    "        'n_trees': [75, 100, 150],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'n_feats': ['sqrt', 'log2'],\n",
    "        'PCA_components': [0.2, 0.5, 0.8],\n",
    "        'svd_solver': ['full'],\n",
    "        'bootstrap': [True],\n",
    "        'strip_accents': ['unicode'],\n",
    "        'stop_words': [sw]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "        \n",
    "best_config.pop('stop_words')\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.5, 'decision_func': 'ovr', 'gamma': 'auto', 'kernel': 'linear', 'name': 'SVC', 'penalty': 100, 'strip_accents': 'unicode', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.24120306526027363 ± 0.03470674848440035\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "params = {'name': [model_name],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'decision_func': ['ovr', 'ovo'],\n",
    "    'PCA_components': [0.5],\n",
    "    'svd_solver': ['full'],\n",
    "    'penalty': [1, 100],\n",
    "    'strip_accents': ['unicode'],\n",
    "    'stop_words': [sw]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "        \n",
    "best_config.pop('stop_words')\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best config is: {'PCA_components': 0.8, 'multi_class': 'auto', 'name': 'Logistic Regression', 'penalty': 'l2', 'solver': 'lbfgs', 'strip_accents': 'unicode', 'svd_solver': 'full'}\n",
      "Total Prediction Accuracy: 0.19345404952344478 ± 0.013175796711970217\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Logistic Regression'\n",
    "params = {'name': [model_name],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'multi_class': ['auto'],\n",
    "    'PCA_components': [0.5, 0.8],\n",
    "    'svd_solver': ['full'],\n",
    "    'strip_accents': ['unicode'],\n",
    "    'stop_words': [sw]\n",
    "}\n",
    "best_accuracy = 0\n",
    "best_std = 0\n",
    "for model_config in ParameterGrid(params):\n",
    "    mean_accuracy, std_accuracy = evaluation.evaluate_model(data, model_config, eval_config, seed=RANDOM_SEED)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_std = std_accuracy\n",
    "        best_config = model_config\n",
    "\n",
    "best_config.pop('stop_words')\n",
    "\n",
    "print('The best config is: {}\\nTotal Prediction Accuracy: {} ± {}'.format(best_config, best_accuracy, best_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.0489672952749598 accuracy 0.5752475247524752\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.9043727873817203 accuracy 0.6138613861386139\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.7391209623475713 accuracy 0.7188118811881188\n",
      "Test  accuracy 0.5968379446640316\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.5361537444075262 accuracy 0.807920792079208\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.4800312879209326 accuracy 0.8435643564356435\n",
      "Test  accuracy 0.608695652173913\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.34010526078742176 accuracy 0.8782178217821782\n",
      "Test  accuracy 0.5849802371541502\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.30596852426483173 accuracy 0.897029702970297\n",
      "Test  accuracy 0.5691699604743082\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.23009958306710623 accuracy 0.904950495049505\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.1944414880264213 accuracy 0.9188118811881189\n",
      "Test  accuracy 0.5770750988142292\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.14481264574720898 accuracy 0.9247524752475248\n",
      "Test  accuracy 0.5731225296442687\n",
      "\n",
      "Accuracy for Fold 1 is: 0.5731\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.1170709618902581 accuracy 0.5643564356435644\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.074874403204505 accuracy 0.5465346534653466\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 1.0599322351883715 accuracy 0.5732673267326732\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 1.0384020061474146 accuracy 0.5831683168316831\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 1.066047074757223 accuracy 0.5544554455445545\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 1.0114003926750244 accuracy 0.5821782178217821\n",
      "Test  accuracy 0.5968379446640316\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.9190800821217965 accuracy 0.6138613861386139\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.7340736959393569 accuracy 0.6930693069306931\n",
      "Test  accuracy 0.5968379446640316\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.623744945709161 accuracy 0.7544554455445545\n",
      "Test  accuracy 0.5533596837944663\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.5768737640437178 accuracy 0.7712871287128713\n",
      "Test  accuracy 0.6007905138339921\n",
      "\n",
      "Accuracy for Fold 2 is: 0.6008\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.0654645365054214 accuracy 0.5811881188118811\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.0080184160959063 accuracy 0.5900990099009901\n",
      "Test  accuracy 0.5968379446640316\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.8573736717381816 accuracy 0.6633663366336634\n",
      "Test  accuracy 0.6047430830039525\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.6045857410672613 accuracy 0.7643564356435644\n",
      "Test  accuracy 0.6324110671936758\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.497778031300372 accuracy 0.8128712871287129\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.4105004016346643 accuracy 0.8564356435643564\n",
      "Test  accuracy 0.5810276679841897\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.2590897337892863 accuracy 0.8910891089108911\n",
      "Test  accuracy 0.5770750988142292\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.22792140119395118 accuracy 0.905940594059406\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.17614724293468506 accuracy 0.9148514851485149\n",
      "Test  accuracy 0.6047430830039525\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.12075979775894895 accuracy 0.9237623762376238\n",
      "Test  accuracy 0.6007905138339921\n",
      "\n",
      "Accuracy for Fold 3 is: 0.6008\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.1394346256659726 accuracy 0.5489614243323442\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.007933280716731 accuracy 0.5845697329376854\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.8094940511729773 accuracy 0.6874381800197824\n",
      "Test  accuracy 0.5753968253968254\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.6145094897099367 accuracy 0.781404549950544\n",
      "Test  accuracy 0.5793650793650793\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.40148485375670934 accuracy 0.8555885262116716\n",
      "Test  accuracy 0.5873015873015872\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.39727943103144486 accuracy 0.8615232443125618\n",
      "Test  accuracy 0.5753968253968254\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.26597040915113734 accuracy 0.90702274975272\n",
      "Test  accuracy 0.5912698412698413\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.23698054101523452 accuracy 0.9159248269040554\n",
      "Test  accuracy 0.6031746031746031\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.17118737113288068 accuracy 0.9198813056379822\n",
      "Test  accuracy 0.5912698412698413\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.1464233600248502 accuracy 0.9268051434223541\n",
      "Test  accuracy 0.5674603174603174\n",
      "\n",
      "Accuracy for Fold 4 is: 0.5675\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.0857860999783193 accuracy 0.5816023738872403\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.0401123105071661 accuracy 0.5835806132542037\n",
      "Test  accuracy 0.5912698412698413\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.9359192694500675 accuracy 0.6379821958456973\n",
      "Test  accuracy 0.5873015873015872\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.7407854884628235 accuracy 0.7260138476755688\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.641307543229869 accuracy 0.7725024727992087\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.5224503621341675 accuracy 0.8239366963402571\n",
      "Test  accuracy 0.6031746031746031\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.4359190957987402 accuracy 0.8486646884272997\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.33762875351849503 accuracy 0.8753709198813056\n",
      "Test  accuracy 0.615079365079365\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.2650407436560458 accuracy 0.9020771513353115\n",
      "Test  accuracy 0.6309523809523809\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.26858339675768156 accuracy 0.897131552917903\n",
      "Test  accuracy 0.6190476190476191\n",
      "\n",
      "Accuracy for Fold 5 is: 0.619\n",
      "Total Prediction Accuracy is: 0.5922 ± 0.0192\n"
     ]
    }
   ],
   "source": [
    "# Check the BERT model\n",
    "bert_name = 'bert-base-multilingual-cased'\n",
    "bert_config = {\n",
    "    'name': bert_name,\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(bert_name),\n",
    "    'max_len': 100,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 10\n",
    "}\n",
    "\n",
    "evaluation.evaluate_model(data, bert_config, eval_config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.1296878790292215 accuracy 0.48217821782178216\n",
      "Test  accuracy 0.5810276679841897\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.9449049937208807 accuracy 0.5702970297029704\n",
      "Test  accuracy 0.5494071146245059\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.6662546022846474 accuracy 0.7108910891089109\n",
      "Test  accuracy 0.5691699604743082\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.4131142388933932 accuracy 0.8148514851485149\n",
      "Test  accuracy 0.5494071146245059\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.25978799330668273 accuracy 0.8693069306930693\n",
      "Test  accuracy 0.5849802371541502\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.2455331687244869 accuracy 0.8831683168316832\n",
      "Test  accuracy 0.5573122529644269\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.24195834103509725 accuracy 0.8900990099009901\n",
      "Test  accuracy 0.541501976284585\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.1154627173714611 accuracy 0.9118811881188119\n",
      "Test  accuracy 0.5059288537549407\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.07009019493469125 accuracy 0.9267326732673268\n",
      "Test  accuracy 0.541501976284585\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.05920605345993068 accuracy 0.9306930693069307\n",
      "Test  accuracy 0.5098814229249011\n",
      "\n",
      "Accuracy for Fold 1 is: 0.5099\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.164329054318075 accuracy 0.48217821782178216\n",
      "Test  accuracy 0.5810276679841897\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.0218336072963055 accuracy 0.5277227722772277\n",
      "Test  accuracy 0.5217391304347826\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.7598433878243439 accuracy 0.6693069306930693\n",
      "Test  accuracy 0.5731225296442687\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.42674850294821143 accuracy 0.7970297029702971\n",
      "Test  accuracy 0.5612648221343873\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.2078589497695083 accuracy 0.8792079207920792\n",
      "Test  accuracy 0.5770750988142292\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.18223165470087446 accuracy 0.8871287128712871\n",
      "Test  accuracy 0.5494071146245059\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.05479241552392358 accuracy 0.9297029702970298\n",
      "Test  accuracy 0.5296442687747035\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.039387860558615394 accuracy 0.9326732673267327\n",
      "Test  accuracy 0.5533596837944663\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.017712522800253268 accuracy 0.9396039603960397\n",
      "Test  accuracy 0.5652173913043478\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.0083091675137045 accuracy 0.9425742574257426\n",
      "Test  accuracy 0.5494071146245059\n",
      "\n",
      "Accuracy for Fold 2 is: 0.5494\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.9318477878040876 accuracy 0.4732673267326733\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 2.3249250565120203 accuracy 0.5138613861386139\n",
      "Test  accuracy 0.6047430830039525\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 2.4599944311459954 accuracy 0.5811881188118811\n",
      "Test  accuracy 0.6403162055335968\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 2.5028722385186555 accuracy 0.7079207920792079\n",
      "Test  accuracy 0.6324110671936758\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 2.4414387493701093 accuracy 0.7029702970297029\n",
      "Test  accuracy 0.616600790513834\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 2.3641669343447487 accuracy 0.7603960396039604\n",
      "Test  accuracy 0.592885375494071\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 2.374034798478132 accuracy 0.7712871287128713\n",
      "Test  accuracy 0.5889328063241106\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 2.401969037220381 accuracy 0.802970297029703\n",
      "Test  accuracy 0.6245059288537549\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 2.456045096803949 accuracy 0.807920792079208\n",
      "Test  accuracy 0.6126482213438734\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 2.516835301735088 accuracy 0.8128712871287129\n",
      "Test  accuracy 0.608695652173913\n",
      "\n",
      "Accuracy for Fold 3 is: 0.6087\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.1800594977506502 accuracy 0.4886251236399604\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.1153554552652705 accuracy 0.4886251236399604\n",
      "Test  accuracy 0.5793650793650793\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 1.0878976977716281 accuracy 0.5301681503461919\n",
      "Test  accuracy 0.5317460317460317\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.9143056937559383 accuracy 0.5885262116716122\n",
      "Test  accuracy 0.5277777777777778\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.6627376127225442 accuracy 0.7279920870425322\n",
      "Test  accuracy 0.5873015873015872\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.49459351857713474 accuracy 0.8051434223541049\n",
      "Test  accuracy 0.5992063492063492\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.3357411593081444 accuracy 0.8516320474777448\n",
      "Test  accuracy 0.5714285714285714\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.19228528953051033 accuracy 0.8882294757665677\n",
      "Test  accuracy 0.5753968253968254\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.12133466026665071 accuracy 0.9159248269040554\n",
      "Test  accuracy 0.5753968253968254\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.11712993367705274 accuracy 0.9129574678536102\n",
      "Test  accuracy 0.5198412698412698\n",
      "\n",
      "Accuracy for Fold 4 is: 0.5198\n",
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.2771159372930452 accuracy 0.45598417408506425\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 1.2613627455365939 accuracy 0.4629080118694362\n",
      "Test  accuracy 0.5793650793650793\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 1.2219558395738677 accuracy 0.5123639960435212\n",
      "Test  accuracy 0.5992063492063492\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 1.1230007492181824 accuracy 0.6201780415430267\n",
      "Test  accuracy 0.5873015873015872\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.9717187964775431 accuracy 0.6874381800197824\n",
      "Test  accuracy 0.5952380952380952\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.85410554331588 accuracy 0.7359050445103857\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.6485110960578121 accuracy 0.7942631058358061\n",
      "Test  accuracy 0.611111111111111\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.5032125924765243 accuracy 0.8456973293768546\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.4473837463214524 accuracy 0.8882294757665677\n",
      "Test  accuracy 0.6071428571428571\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.42416747750377093 accuracy 0.884272997032641\n",
      "Test  accuracy 0.5912698412698413\n",
      "\n",
      "Accuracy for Fold 5 is: 0.5913\n",
      "Total Prediction Accuracy is: 0.5558 ± 0.0387\n"
     ]
    }
   ],
   "source": [
    "# Check the BERT model but adding weighting so that the penalization for mistaken the smaller classes is bigger\n",
    "bert_name = 'bert-base-multilingual-cased'\n",
    "bert_config = {\n",
    "    'name': bert_name,\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(bert_name),\n",
    "    'max_len': 100,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 10\n",
    "}\n",
    "\n",
    "evaluation.evaluate_model(data, bert_config, eval_config, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_FILE = 'SBW-vectors-300-min5.bin'\n",
    "\n",
    "word2vecs = KeyedVectors.load_word2vec_format(os.path.join(DATA_PATH, WV_FILE), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = np.array(data.text.apply(lambda s: composition.compose(nltk.word_tokenize(s), word2vecs)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.3373 ± 0.0154\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(comps, data['toxicity_degree'].values):\n",
    "    train_x = comps[train_index, :]\n",
    "    test_x = comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(128, 64), solver='lbfgs', learning_rate='adaptive',\n",
    "                        learning_rate_init=2e-3, random_state=RANDOM_SEED, max_iter=100)\n",
    "    mlp.fit(train_x, train_y)\n",
    "    pred_y = mlp.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "What I've observed from tweeking the parameters is that the lbfgs solver increases noticeably the f1-score (it is recommended in the sklearn documentation for small datasets), together with the number of iterations/epochs that we let the model train. The learning rate does not have a really big impact on performance when changed from invscaling to adaptive. The best activation function so far seems to be tanh.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.3501 ± 0.0325\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(comps, data['toxicity_degree'].values):\n",
    "    train_x = comps[train_index, :]\n",
    "    test_x = comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=100, class_weight=None, random_state=RANDOM_SEED, solver='lbfgs')\n",
    "    lr.fit(train_x, train_y)\n",
    "    pred_y = lr.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "It is interesting that the result actually gets worse when the class_weight parameter is set to balance to account for imbalanced distribution in the data. The results slightly improve when the penalty value is increased to 100. With regard to the solver, lbfgs does a good work for this model and dataset again.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's see the effect of using other compositionality function such as the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_comps = np.array(data.text.apply(lambda s: composition.compose(nltk.word_tokenize(s), word2vecs, \n",
    "                                                                   comp_func=composition._average)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.2994 ± 0.0575\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(avg_comps, data['toxicity_degree'].values):\n",
    "    train_x = avg_comps[train_index, :]\n",
    "    test_x = avg_comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    mlp = MLPClassifier(activation='identity', hidden_layer_sizes=(256, 64), solver='lbfgs', \n",
    "                        learning_rate='invscaling', learning_rate_init=2e-3, random_state=RANDOM_SEED, max_iter=100)\n",
    "    mlp.fit(train_x, train_y)\n",
    "    pred_y = mlp.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Using the same parameters as in the previous case, the result gets worse when the compositionality function is the average of the word_vectors. Increasing the size of the hidden layer slightly improves the accuracy score.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.3029 ± 0.05\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(avg_comps, data['toxicity_degree'].values):\n",
    "    train_x = avg_comps[train_index, :]\n",
    "    test_x = avg_comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=100, class_weight=None, random_state=RANDOM_SEED, solver='lbfgs')\n",
    "    lr.fit(train_x, train_y)\n",
    "    pred_y = lr.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about removing the stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = data.text.apply(lambda s: composition.compose(nltk.word_tokenize(s), word2vecs, \n",
    "                                                      comp_func=composition._average,\n",
    "                                                      stopwords=sw)).tolist()\n",
    "comps = [np.zeros(300,) if c is None else c for c in comps]\n",
    "comps = np.array(comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.276 ± 0.0266\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(comps, data['toxicity_degree'].values):\n",
    "    train_x = comps[train_index, :]\n",
    "    test_x = comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    mlp = MLPClassifier(activation='identity', hidden_layer_sizes=(256, 64), solver='lbfgs', \n",
    "                        learning_rate='invscaling', learning_rate_init=2e-3, random_state=RANDOM_SEED, max_iter=100)\n",
    "    mlp.fit(train_x, train_y)\n",
    "    pred_y = mlp.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction Accuracy is: 0.2813 ± 0.0316\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_SEED)\n",
    "accuracies = []\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(comps, data['toxicity_degree'].values):\n",
    "    train_x = comps[train_index, :]\n",
    "    test_x = comps[test_index, :]\n",
    "    train_y = data['toxicity_degree'].values[train_index]\n",
    "    test_y = data['toxicity_degree'].values[test_index]\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=100, class_weight=None, random_state=RANDOM_SEED, solver='lbfgs')\n",
    "    lr.fit(train_x, train_y)\n",
    "    pred_y = lr.predict(test_x)\n",
    "    \n",
    "    accuracies.append(f1_score(test_y, pred_y, labels=data['toxicity_degree'].unique(), average='macro'))\n",
    "    \n",
    "print('Total Prediction Accuracy is:', np.round(np.mean(accuracies), 4), '\\u00B1', np.round(np.std(accuracies), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
